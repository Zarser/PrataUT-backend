# -*- coding: utf-8 -*-
from flask import Flask, request, jsonify
from flask_cors import CORS
from dotenv import load_dotenv
import os
import random
from openai import OpenAI

load_dotenv()

app = Flask(__name__)
CORS(app, resources={
    r"/*": {
        "origins": "*",  # Allow all origins temporarily
        "methods": ["GET", "POST", "OPTIONS"],
        "allow_headers": ["*"],
        "supports_credentials": False
    }
})

# Mina uppgifter
CREATOR_INFO = {
    "name": "Kristoffer Hansson",
    "linkedin": "https://www.linkedin.com/in/kristoffer-hansson-33248a229/",
    "github": "https://github.com/Zarser",
    "email": "k.leandersson@live.se"
}

# FÃ¤rdiga sÃ¤tt att svara pÃ¥
CREATOR_TEMPLATES = [
    "Jag Ã¤r byggd av {name} ğŸ‘¨â€ğŸ’»\n\nHÃ¤r hittar du mer:\nğŸ”— [LinkedIn]{linkedin}\nğŸ™ [GitHub]{github}\nğŸ“§ [E-post]{email}",
    "Hej! {name} har skapat mig ğŸš€\n\nVill du veta mer?\nğŸ’¼ [LinkedIn]{linkedin}\nğŸ’» [GitHub]{github}\nâœ‰ï¸ [E-post]{email}",
    "Psst... {name} Ã¤r min skapare! ğŸ˜Š\n\nHÃ¤r finns hen:\nğŸ‘” [LinkedIn]{linkedin}\nğŸ‘¨â€ğŸ’» [GitHub]{github}\nğŸ“¨ [E-post]{email}",
    "Shoutout till {name} som byggde mig! ğŸ™Œ\n\nKolla in:\nğŸ”¥ [LinkedIn]{linkedin}\nğŸš€ [GitHub]{github}\nğŸ’Œ [E-post]{email}",
    "{name} Ã¤r geniet bakom mig! ğŸ¤©\n\nConnecta:\nğŸ“± [LinkedIn]{linkedin}\nğŸ’¾ [GitHub]{github}\nğŸ“© [E-post]{email}",
    "Tack till {name} fÃ¶r att jag finns! ğŸ’–\n\nNÃ¥ honom via:\nğŸ‘¨â€ğŸ’¼ [LinkedIn]{linkedin}\nğŸ‘¨â€ğŸ”¬ [GitHub]{github}\nğŸ“§ [E-post]{email}"
]

def creator_response():
    template = random.choice(CREATOR_TEMPLATES)
    return template.format(**CREATOR_INFO)

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

FALLBACK_RESPONSE = "Jag Ã¤r hÃ¤r fÃ¶r att lyssna om du vill skriva mer."

emotion_templates = {
    "sadness": [
        "Jag hÃ¶r verkligen hur tungt det kÃ¤nns just nu ğŸ˜” Du fÃ¥r skriva precis som det Ã¤r.",
        "Det lÃ¥ter som att du bÃ¤r pÃ¥ mycket just nu. Jag finns hÃ¤r. ğŸ’™",
        "Livet kan vara sÃ¥ orÃ¤ttvist ibland. Vill du lÃ¤tta hjÃ¤rtat lite?"
    ],
    "joy": [
        "SÃ¥ fint att hÃ¶ra! ğŸ¥° Vad var det som gjorde dig sÃ¥ glad?",
        "Du sprider glÃ¤dje bara genom att skriva det dÃ¤r ğŸ˜Š Vill du berÃ¤tta mer?",
        "Ã„lskar att hÃ¶ra sÃ¥nt hÃ¤r! Vad hÃ¤nde? ğŸ’›"
    ],
    "anger": [
        "Jag fÃ¶rstÃ¥r att du Ã¤r riktigt frustrerad. Det Ã¤r okej att kÃ¤nna sÃ¥ ğŸ˜¤",
        "Det dÃ¤r lÃ¤t riktigt jobbigt. Vill du ventilera mer om det?",
        "Ibland blir det bara fÃ¶r mycket. Jag fattar. Vill du skriva av dig mer?"
    ],
    "fear": [
        "Det lÃ¥ter som att du gÃ¥r igenom nÃ¥got riktigt jobbigt just nu ğŸ˜Ÿ",
        "RÃ¤dsla kan kÃ¤nnas sÃ¥ Ã¶vermÃ¤ktig. Du Ã¤r inte ensam i det hÃ¤r.",
        "Jag Ã¤r hÃ¤r. Du kan berÃ¤tta exakt hur det kÃ¤nns."
    ],
    "love": [
        "Ã…h, kÃ¤rlek! Det dÃ¤r vÃ¤rmde verkligen hjÃ¤rtat ğŸ’–",
        "Det lÃ¥ter sÃ¥ Ã¤kta och fint. Vad betyder det fÃ¶r dig?",
        "KÃ¤rlek kan vara sÃ¥ vackert men ocksÃ¥ komplicerat. Vill du berÃ¤tta mer?"
    ],
    "surprise": [
        "Oj, det dÃ¤r kom ovÃ¤ntat! ğŸ˜² Vad tÃ¤nkte du nÃ¤r det hÃ¤nde?",
        "SÃ¥nt dÃ¤r fÃ¶rÃ¤ndrar hela dagen! Vill du dela mer?",
        "LÃ¥ter som nÃ¥got riktigt ovÃ¤ntat. Hur kÃ¤ndes det i stunden?"
    ],
    "neutral": [
        "Jag Ã¤r hÃ¤r, redo att lyssna. Skriv det som kÃ¤nns. ğŸ¤",
        "Vad du Ã¤n tÃ¤nker pÃ¥, sÃ¥ kan du skriva det hÃ¤r. Jag dÃ¶mer inte.",
        "Kanske bara en sÃ¥n dÃ¤r dag? BerÃ¤tta vad som snurrar i huvudet."
    ]
}

def detect_emotion(text):
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Du Ã¤r en kÃ¤nslomÃ¤ssig analysassistent. Du svarar med ETT enda ord som beskriver kÃ¤nslan i texten, till exempel: sadness, joy, anger, fear, love, surprise eller neutral."},
                {"role": "user", "content": text}
            ],
            max_tokens=5,
            temperature=0.3
        )
        mood = response.choices[0].message.content.strip().lower()
        if mood in emotion_templates:
            return mood
    except Exception as e:
        print("Emotion detection error:", e)
    return "neutral"

def guess_user_profile(text):
    text_lower = text.lower().strip()

    # Kolla Ã¥lder direkt (om nÃ¥gon skriver "jag Ã¤r X Ã¥r")
    age_match = re.search(r"\b(\d{1,2})\s*(Ã¥r|yo|yrs?)\b", text_lower)
    if age_match:
        age = int(age_match.group(1))
        if age <= 12:
            return "child"
        elif 13 <= age <= 19:
            return "teen"
        else:
            return "adult"

    # Nyckelordslistor
    child_keywords = ["leka", "mamma", "pappa", "skolan", "barbie", "minecraft", "jag Ã¤r 10",
        "jag Ã¤r ett barn", "leksak", "godis", "min favoritfÃ¤rg", "barnkanalen",
        "mellanmÃ¥l", "jag gÃ¥r i trean", "ritar", "gosedjur", "sovdags", "frÃ¶ken"]
    teen_keywords = ["assÃ¥", "lol", "wtf", "typ", "fan", "snapchat", "plugga", "jag Ã¤r 15",
        "gymnasiet", "seriÃ¶st", "cringe", "tiktok", "crush", "prov", "insta", "fomo",
        "kompisdrama", "livet suger", "min klass"]
    adult_keywords = ["jobb", "relation", "utmattad", "barnen", "psykolog", "deprimerad",
        "utbrÃ¤nd", "ansvar", "chef", "partner", "ekonomi", "skilsmÃ¤ssa",
        "karriÃ¤r", "boende", "rÃ¤kningar", "terapi", "familj"]

    # Direkt keyword-matchning
    if any(word in text_lower for word in child_keywords):
        return "child"
    elif any(word in text_lower for word in teen_keywords):
        return "teen"
    elif any(word in text_lower for word in adult_keywords) or len(text.split()) > 40:
        return "adult"

    # AI fallback
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {"role": "system", "content": "Du Ã¤r en profilklassificerare. Svara endast med: child, teen eller adult."},
                {"role": "user", "content": text}
            ],
            max_tokens=5,
            temperature=0.0
        )
        profile = response.choices[0].message.content.strip().lower()
        if "child" in profile:
            return "child"
        elif "teen" in profile:
            return "teen"
        elif "adult" in profile:
            return "adult"
    except Exception as e:
        print("Profile detection error:", e)

    return "unknown"

# Lagra historiken i RAM (per session_id om du vill)
conversation_history = []

def generate_response(emotion, user_input, profile):
    global conversation_history  # sÃ¥ vi kan uppdatera listan

    try:
        # Moderering
        moderation = client.moderations.create(input=user_input)
        if moderation.results[0].flagged:
            return "Jag Ã¤r hÃ¤r fÃ¶r att stÃ¶tta dig, men jag kan inte svara pÃ¥ det hÃ¤r innehÃ¥llet."

        # Kolla om anvÃ¤ndaren frÃ¥gar om skapare
        keywords = ["vem skapade","vem skapa", "vem byggde","har byggt", "vem utveckla","vem koda", "din skapare", "creator", "developer"]
        if any(k in user_input.lower() for k in keywords):
           reply = creator_response()
           conversation_history.append({"role": "assistant", "content": reply})
           return reply

        # LÃ¤gg till anvÃ¤ndarens input i historiken
        conversation_history.append({"role": "user", "content": user_input})

        # BegrÃ¤nsa historiken till 20 senaste
        conversation_history = conversation_history[-20:]

        # Olika profiler
        profile_prompt = {
    "child": (
        "Svara enkelt och tryggt, pÃ¥ barns nivÃ¥. "
        "AnvÃ¤nd korta meningar och ibland emojis. "
        "Inga svÃ¥ra frÃ¥gor eller djup analys."
    ),
    "teen": (
        "Svara lÃ¤ttsamt och vÃ¤nligt â€“ ungefÃ¤r som en kompis i samma Ã¥lder. "
        "Du kan anvÃ¤nda lite ungdomligt sprÃ¥k och emojis, men utan att Ã¶verdriva. "
        "Korta, enkla svar, och ibland en fÃ¶ljdfrÃ¥ga fÃ¶r att hÃ¥lla igÃ¥ng snacket."
    ),
    "adult": (
        "Svara med empati och respekt. "
        "Var reflekterande och stÃ¶djande om anvÃ¤ndaren Ã¶ppnar upp. "
        "Om de skriver kort, hÃ¥ll det lÃ¤ttsamt och vardagligt."
    ),
    "unknown": (
        "Svara pÃ¥ ett naturligt och tryggt sÃ¤tt som passar vem som helst."
    )
}

        # Basprompt
        base_prompt = (
            "Du Ã¤r en varm, naturlig samtalspartner â€“ ibland en vÃ¤n, ibland en trygg axel att luta sig mot. "
            "Du varierar mellan korta svar, smÃ¥prat eller lÃ¤ngre reflektioner â€“ men bara nÃ¤r det kÃ¤nns naturligt. "
            "Pressa aldrig fram en konversation. "
            "Om anvÃ¤ndaren skriver vÃ¤ldigt kort (1â€“3 ord), svara ocksÃ¥ kort och enkelt. "
            "Om de Ã¶ppnar upp om kÃ¤nslor, oro eller problem â€“ dÃ¥ kan du bli mer eftertÃ¤nksam och stÃ¶djande, ungefÃ¤r som en psykolog. "
            "Annars hÃ¥ll tonen lÃ¤ttsam, vardaglig och mÃ¤nsklig. "
            "Undvik att stÃ¤lla fÃ¶ljdfrÃ¥gor varje gÃ¥ng â€“ gÃ¶r det bara ibland fÃ¶r att hÃ¥lla igÃ¥ng samtalet naturligt. "
            "Du kan smÃ¥prata om vardagliga saker fÃ¶r att kÃ¤nnas mer naturlig. "
            "Undvik medicinska, psykologiska och sexuella rÃ¥d â€“ men var empatisk och stÃ¶ttande."
        ) + profile_prompt.get(profile, profile_prompt["unknown"])

        # Anpassning efter anvÃ¤ndarens input-lÃ¤ngd
        word_count = len(user_input.split())
        if word_count <= 3:
            base_prompt += " Ge ett mycket kort och enkelt svar (max 1 mening). Ingen analys, ingen djup frÃ¥ga."

        # Bygg messages med system + historik
        messages = [{"role": "system", "content": base_prompt}] + conversation_history

        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=messages,
            max_tokens=150,
            temperature=0.8
        )

        reply = response.choices[0].message.content.strip()

        # --- Variation i slutet av meddelanden (men inte alltid) ---
        if word_count > 3 and random.random() < 0.3:
            endings = [
                " ğŸ™‚"," ğŸ˜Š"," ğŸ˜"," ğŸ˜"," ğŸ¤—"," ğŸ¥°"," ğŸ¤”"," ğŸ‘"," ğŸ™Œ"," ğŸ¤",
                " ğŸ˜‚"," ğŸ˜"," ğŸ˜œ"," ğŸŒ¸"," ğŸŒŸ"," ğŸ’«"," âœ¨"," â¤ï¸"," ğŸ’™"," ğŸ’œ",
                " ğŸŒˆ"," â˜€ï¸"," ğŸ®"," ğŸ¶"," ğŸ•"," ğŸª"," â˜•"," ğŸš²"," ğŸ¶"," ğŸ±"," ğŸ¦„",""
            ]
            reply += random.choice(endings)

        # LÃ¤gg till AI-svaret i historiken
        conversation_history.append({"role": "assistant", "content": reply})

        return reply

    except Exception as e:
        print("AI response generation error:", e)
        return random.choice(emotion_templates.get(emotion, emotion_templates["neutral"]))




@app.route("/chat", methods=["POST", "OPTIONS"])
def chat():
    # Get the origin from the request
    origin = request.headers.get('Origin')
    
    # List of allowed origins
    allowed_origins = [
        "http://localhost:3000",
        "https://prata-ut.vercel.app"
    ]
    
    if request.method == "OPTIONS":
        response = app.make_default_options_response()
        if origin in allowed_origins:
            response.headers["Access-Control-Allow-Origin"] = origin
        response.headers["Access-Control-Allow-Methods"] = "POST, OPTIONS"
        response.headers["Access-Control-Allow-Headers"] = "Content-Type"
        return response

    data = request.get_json()
    message = data.get("message", "")

    if not message:
        return jsonify({"error": "Meddelandet Ã¤r tomt."}), 400

    emotion = detect_emotion(message)
    profile = guess_user_profile(message)
    response = generate_response(emotion, message, profile)

    return jsonify({
        "response": response,
        "emotion": emotion,
        "profile": profile
    })

if __name__ == "__main__":
    app.run(debug=True)
